{"version":3,"file":"chunks/scratch-vm_src_extensions_scratch3neuralnet_tf-worker_js.81f4b193d4e4bd16a4fa.js","mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACVA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://GUI/webpack/universalModuleDefinition","webpack://GUI/../scratch-vm/src/extensions/scratch3neuralnet/tf-worker.js"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"GUI\"] = factory();\n\telse\n\t\troot[\"GUI\"] = factory();\n})(self, () => {\nreturn ","importScripts('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js');\n\nlet model = null;\nlet isBackendReady = false;\n\n(async () => {\n    try {\n        await tf.setBackend('webgl');\n        await tf.ready();\n        isBackendReady = true;\n    } catch (e) {\n        try {\n            await tf.setBackend('cpu');\n            await tf.ready();\n            isBackendReady = true;\n        } catch (e2) {\n            isBackendReady = false;\n        }\n    }\n    \n    if (tf.getBackend() === 'webgl') {\n        tf.env().set('WEBGL_DELETE_TEXTURE_THRESHOLD', 0);\n        tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);\n    }\n})();\n\nself.onmessage = async (event) => {\n    const { id, type, payload } = event.data;\n\n    try {\n        if (type === 'loadModel') {\n            if (!isBackendReady) {\n                await tf.ready();\n                isBackendReady = true;\n            }\n            \n            if (model) {\n                model.dispose();\n                model = null;\n            }\n            \n            const modelJson = JSON.parse(new TextDecoder().decode(payload.jsonBuffer));\n            \n            let topology = modelJson.modelTopology;\n            \n            if (topology) {\n                if (topology.model_config && topology.model_config.class_name) {\n                    topology = topology.model_config;\n                }\n                else if (topology.modelConfig && topology.modelConfig.class_name) {\n                    topology = topology.modelConfig;\n                }\n                \n                if (topology.model_config && topology.model_config.class_name) {\n                    topology = topology.model_config;\n                }\n\n                if (topology.config && topology.config.layers) {\n                    topology.config.layers.forEach(layer => {\n                        if (layer.inbound_nodes && Array.isArray(layer.inbound_nodes)) {\n                            const needsConversion = layer.inbound_nodes.some(node => \n                                node && typeof node === 'object' && ('args' in node || 'kwargs' in node)\n                            );\n                            \n                            if (needsConversion) {\n                                layer.inbound_nodes = layer.inbound_nodes.map(node => {\n                                    if (!node || typeof node !== 'object') {\n                                        return node;\n                                    }\n                                    \n                                    if ('args' in node) {\n                                        const args = node.args || [];\n                                        const kwargs = node.kwargs || {};\n                                        \n                                        if (Array.isArray(args)) {\n                                            return args.map(arg => {\n                                                if (arg && typeof arg === 'object' && 'keras_history' in arg) {\n                                                    const history = arg.keras_history;\n                                                    return [history[0], history[1], history[2], kwargs];\n                                                }\n                                                return [arg, 0, 0, kwargs];\n                                            });\n                                        }\n                                    }\n                                    \n                                    return node;\n                                });\n                            }\n                        }\n                    });\n                }\n            }\n\n            const modelArtifacts = {\n                modelTopology: topology,\n                weightSpecs: modelJson.weightsManifest.flatMap(group => group.weights),\n                weightData: payload.weightsBuffer,\n            };\n            \n            if (!tf.getBackend()) {\n                throw new Error('TensorFlow.js backend is not initialized. This should not happen.');\n            }\n            \n            let progressTimeout;\n\n            const progressCallback = (fraction) => {\n                clearTimeout(progressTimeout);\n                progressTimeout = setTimeout(() => {\n                    const errorMessage = `ЗАВИСАНИЕ! Загрузка остановилась более 15 секунд. Вероятная причина: нехватка памяти GPU (WebGL). Попробуйте перезагрузить браузер.`;\n                    self.postMessage({\n                        id: id,\n                        type: 'error',\n                        payload: errorMessage\n                    });\n                }, 15000);\n            };\n            \n            try {\n                const ioHandler = tf.io.fromMemory(modelArtifacts);\n                model = await tf.loadLayersModel(ioHandler, { onProgress: progressCallback });\n                clearTimeout(progressTimeout);\n            } catch (error) {\n                clearTimeout(progressTimeout);\n                throw error;\n            }\n\n            const inputShape = model.inputs[0].shape;\n            \n            const response = {\n                height: inputShape[1] || 0,\n                width: inputShape[2] || 0\n            };\n            \n            self.postMessage({ id: id, type: 'modelLoaded', payload: response });\n\n        } else if (type === 'predict') {\n            if (!model) { \n                throw new Error('Model is not loaded in the worker.'); \n            }\n            \n            const { imageData, width, height } = payload;\n            \n            const tensor = tf.tidy(() => {\n                const imgTensor = tf.tensor3d(imageData, [height, width, 4])\n                                    .slice([0, 0, 0], [height, width, 3]);\n                return imgTensor.toFloat().div(255.0).expandDims(0);\n            });\n            \n            const prediction = model.predict(tensor);\n            const probsData = await prediction.data();\n            \n            tensor.dispose();\n            prediction.dispose();\n            \n            self.postMessage({ \n                id: id, \n                type: 'predictionResult', \n                payload: Array.from(probsData) \n            });\n        }\n    } catch (error) {\n        self.postMessage({\n            id: id,\n            type: 'error',\n            payload: error.message\n        });\n    }\n};"],"names":[],"sourceRoot":""}